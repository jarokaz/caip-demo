{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operationalizing training with Kubeflow Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the current version of KFP SDK is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://storage.googleapis.com/ml-pipeline/release/0.1.26/kfp.tar.gz\n",
      "  Using cached https://storage.googleapis.com/ml-pipeline/release/0.1.26/kfp.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.15 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (5.1.1)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-storage>=1.13.0 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (1.16.1)\n",
      "Requirement already satisfied, skipping upgrade: kubernetes<=9.0.0,>=8.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (9.0.0)\n",
      "Requirement already satisfied, skipping upgrade: PyJWT>=1.6.4 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: cryptography>=2.4.2 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (1.6.3)\n",
      "Requirement already satisfied, skipping upgrade: requests_toolbelt>=0.8.0 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (0.8.0)\n",
      "Requirement already satisfied, skipping upgrade: kfp-server-api<=0.1.25,>=0.1.18 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (0.1.18.3)\n",
      "Requirement already satisfied, skipping upgrade: argo-models==2.2.1a in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (2.2.1a0)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: tabulate==0.8.3 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: click==7.0 in /opt/anaconda3/lib/python3.7/site-packages (from kfp==0.1.25) (7.0)\n",
      "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.25) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /opt/anaconda3/lib/python3.7/site-packages (from google-cloud-storage>=1.13.0->kfp==0.1.25) (0.3.2)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/lib/python3.7/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (0.56.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /opt/anaconda3/lib/python3.7/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in /opt/anaconda3/lib/python3.7/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (40.8.0)\n",
      "Requirement already satisfied, skipping upgrade: asn1crypto>=0.21.0 in /opt/anaconda3/lib/python3.7/site-packages (from cryptography>=2.4.2->kfp==0.1.25) (0.24.0)\n",
      "Requirement already satisfied, skipping upgrade: cffi!=1.11.3,>=1.8 in /opt/anaconda3/lib/python3.7/site-packages (from cryptography>=2.4.2->kfp==0.1.25) (1.12.2)\n",
      "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.1.25) (3.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.1.25) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /opt/anaconda3/lib/python3.7/site-packages (from google-auth>=1.6.1->kfp==0.1.25) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.1.25) (19.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in /opt/anaconda3/lib/python3.7/site-packages (from jsonschema>=3.0.1->kfp==0.1.25) (0.14.11)\n",
      "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.11.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==0.1.25) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<=9.0.0,>=8.0.0->kfp==0.1.25) (3.0.2)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in /opt/anaconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.4.2->kfp==0.1.25) (2.19)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /opt/anaconda3/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp==0.1.25) (0.4.5)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.11.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==0.1.25) (3.9.0)\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/anaconda3/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.11.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==0.1.25) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/anaconda3/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.11.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp==0.1.25) (2018.9)\n",
      "Building wheels for collected packages: kfp\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-qqf_65p1/wheels/89/0c/5f/7bcd7449cc45156ddbdd7c288cbc8ecdfb6662e226e3927b21\n",
      "Successfully built kfp\n",
      "Installing collected packages: kfp\n",
      "  Found existing installation: kfp 0.1.25\n",
      "    Uninstalling kfp-0.1.25:\n",
      "      Successfully uninstalled kfp-0.1.25\n",
      "Successfully installed kfp-0.1.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "RELEASE = \"0.1.26\"\n",
    "RELEASE_URL = \"https://storage.googleapis.com/ml-pipeline/release/{}/kfp.tar.gz\".format(RELEASE) \n",
    "%pip install $RELEASE_URL --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kfp\n",
    "from kfp import gcp\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training container image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_IMAGE_FOLDER = '../training_image'\n",
    "\n",
    "os.makedirs(TRAINING_IMAGE_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../training_image/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAINING_IMAGE_FOLDER/Dockerfile\n",
    "\n",
    "FROM gcr.io/jk-demo1/sklearn-cpu:latest\n",
    "WORKDIR /app\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../training_image/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAINING_IMAGE_FOLDER/train.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import joblib\n",
    "import fire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def train(job_dir, data_path, n_features_options, l2_reg_options):\n",
    "    \n",
    "  # Load data from GCS\n",
    "  df_train = pd.read_csv(data_path)\n",
    "\n",
    "  y = df_train.octane\n",
    "  X = df_train.drop('octane', axis=1)\n",
    "    \n",
    "  # Configure a training pipeline\n",
    "  pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('regress', Ridge())\n",
    "  ])\n",
    "\n",
    "  # Configure a parameter grid\n",
    "  param_grid = [\n",
    "    {\n",
    "      'reduce_dim__n_components': n_features_options,\n",
    "      'regress__alpha': l2_reg_options\n",
    "    }\n",
    "  ]\n",
    "\n",
    "  # Tune hyperparameters\n",
    "  grid = GridSearchCV(pipeline, cv=10, n_jobs=None, param_grid=param_grid, scoring='neg_mean_squared_error', iid=False)\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  logging.info(\"Best estimator: {}\".format(grid.best_params_))\n",
    "  logging.info(\"Best score: {}\".format(grid.best_score_))\n",
    "    \n",
    "  # Retrain the best model on a full dataset\n",
    "  best_estimator = grid.best_estimator_\n",
    "  trained_pipeline = best_estimator.fit(X, y)\n",
    "\n",
    "  # Save the model\n",
    "  model_filename = 'model.joblib'\n",
    "  joblib.dump(value=trained_pipeline, filename=model_filename)\n",
    "  gcs_model_path = \"{}/{}\".format(job_dir, model_filename)\n",
    "  subprocess.check_call(['gsutil', 'cp', model_filename, gcs_model_path], stderr=sys.stdout)\n",
    "  logging.info(\"Saved model in: {}\".format(gcs_model_path)) \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "  logging.basicConfig(level=logging.INFO)\n",
    "  fire.Fire(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 2.0 KiB before compression.\n",
      "Uploading tarball of [../training_image] to [gs://jk-demo1_cloudbuild/source/1566938464.36-5002fe55cdc946a78fc9dad65b0fe1ef.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jk-demo1/builds/aa196a47-bf0e-4428-abc5-0971c37ddafe].\n",
      "Logs are available at [https://console.cloud.google.com/gcr/builds/aa196a47-bf0e-4428-abc5-0971c37ddafe?project=826865698127].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"aa196a47-bf0e-4428-abc5-0971c37ddafe\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jk-demo1_cloudbuild/source/1566938464.36-5002fe55cdc946a78fc9dad65b0fe1ef.tgz#1566938464819369\n",
      "Copying gs://jk-demo1_cloudbuild/source/1566938464.36-5002fe55cdc946a78fc9dad65b0fe1ef.tgz#1566938464819369...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.                                      \n",
      "BUILD\n",
      "Pulling image: gcr.io/kaniko-project/executor:latest\n",
      "latest: Pulling from kaniko-project/executor\n",
      "Digest: sha256:584a8d90679211d9b09465d778990ec15965cf78f57f197e973d57d14b08eb81\n",
      "Status: Downloaded newer image for gcr.io/kaniko-project/executor:latest\n",
      "gcr.io/kaniko-project/executor:latest\n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name gcr.io/jk-demo1/sklearn-cpu:latest to gcr.io/jk-demo1/sklearn-cpu:latest \n",
      "\u001b[36mINFO\u001b[0m[0000] Resolved base name gcr.io/jk-demo1/sklearn-cpu:latest to gcr.io/jk-demo1/sklearn-cpu:latest \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image gcr.io/jk-demo1/sklearn-cpu:latest \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:9641e43af0816270b5c797fd6009d6b65bd9a9775f014f3b58ea0e37d617bb3a: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image gcr.io/jk-demo1/sklearn-cpu:latest \n",
      "\u001b[36mINFO\u001b[0m[0000] Built cross stage deps: map[]                \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image gcr.io/jk-demo1/sklearn-cpu:latest \n",
      "\u001b[36mINFO\u001b[0m[0000] Error while retrieving image from cache: getting file info: stat /cache/sha256:9641e43af0816270b5c797fd6009d6b65bd9a9775f014f3b58ea0e37d617bb3a: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0000] Downloading base image gcr.io/jk-demo1/sklearn-cpu:latest \n",
      "\u001b[36mINFO\u001b[0m[0000] Using files from context: [/workspace/train.py] \n",
      "\u001b[36mINFO\u001b[0m[0000] Skipping unpacking as no commands require it. \n",
      "\u001b[36mINFO\u001b[0m[0000] Taking snapshot of full filesystem...        \n",
      "\u001b[36mINFO\u001b[0m[0000] WORKDIR /app                                 \n",
      "\u001b[36mINFO\u001b[0m[0000] cmd: workdir                                 \n",
      "\u001b[36mINFO\u001b[0m[0000] Changed working directory to /app            \n",
      "\u001b[36mINFO\u001b[0m[0000] Creating directory /app                      \n",
      "\u001b[36mINFO\u001b[0m[0000] Taking snapshot of files...                  \n",
      "\u001b[36mINFO\u001b[0m[0000] Using files from context: [/workspace/train.py] \n",
      "\u001b[36mINFO\u001b[0m[0000] COPY train.py .                              \n",
      "\u001b[36mINFO\u001b[0m[0000] Taking snapshot of files...                  \n",
      "\u001b[36mINFO\u001b[0m[0000] ENTRYPOINT [\"python\", \"train.py\"]            \n",
      "\u001b[36mINFO\u001b[0m[0000] No files changed in this command, skipping snapshotting. \n",
      "PUSH\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                              IMAGES  STATUS\n",
      "aa196a47-bf0e-4428-abc5-0971c37ddafe  2019-08-27T20:41:05+00:00  13S       gs://jk-demo1_cloudbuild/source/1566938464.36-5002fe55cdc946a78fc9dad65b0fe1ef.tgz  -       SUCCESS\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = !gcloud config list project --format \"value(core.project)\"\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "IMAGE_REPO_NAME=\"octane-regression-training\"\n",
    "IMAGE_TAG=\"latest\"\n",
    "IMAGE_URI=\"gcr.io/{}/{}:{}\".format(PROJECT_ID, IMAGE_REPO_NAME, IMAGE_TAG)\n",
    "\n",
    "!gcloud builds submit --tag $IMAGE_URI $TRAINING_IMAGE_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = !gcloud config list project --format \"value(core.project)\"\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "TRAIN_COMPONENT_SPEC=\"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/gcp/ml_engine/train/component.yaml\"\n",
    "mlengine_train_op = kfp.components.load_component_from_url(TRAIN_COMPONENT_SPEC)\n",
    "\n",
    "REGION = 'us-central1'\n",
    "JOB_ID_PREFIX=\"OCTANE_PREDICTOR_TRAINING\"\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "    name=\"octane_predictor_training\",\n",
    "    description=\"Cloud AI Platform Training and Deployment\")\n",
    "def pipeline(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=REGION,\n",
    "    job_dir=\"\",\n",
    "    args=\"\"):\n",
    "    \n",
    "  train_task = mlengine_train_op(\n",
    "      project_id=project_id,\n",
    "      region=region,\n",
    "      args=args,\n",
    "      job_dir=job_dir,\n",
    "      job_id_prefix=JOB_ID_PREFIX,\n",
    "      master_image_uri=IMAGE_URI,\n",
    "   ).apply(gcp.use_gcp_secret('user-gcp-sa'))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_filename = pipeline._pipeline_name + '.zip'\n",
    "kfp.compiler.Compiler().compile(pipeline, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the run\n",
    "### Fetch GKE credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cluster endpoint and auth data.\n",
      "kubeconfig entry generated for kf-gke-cluster.\n"
     ]
    }
   ],
   "source": [
    "CLUSTER_NAME = \"kf-gke-cluster\"\n",
    "ZONE = \"us-central1-a\"\n",
    "\n",
    "!gcloud container clusters get-credentials $CLUSTER_NAME --zone $ZONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a KFP experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-27 20:42:10:INFO:Creating experiment Octane Predictor Training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Experiment link <a href=\"/pipeline/#/experiments/details/f873274a-1524-4d69-be49-8bf3b4aefb04\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EXPERIMENT_NAME = \"Octane Predictor Training\"\n",
    "\n",
    "client = kfp.Client()\n",
    "experiment = client.create_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/2612de4d-c90b-11e9-ad8b-42010a80018b\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_name =  'run_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "JOB_DIR = \"gs://caip-demo-jobdir/\"\n",
    "ARGS = json.dumps([\n",
    "    '--data-path', 'gs://caip-demo-datasets/gasdata/gasdata.csv',\n",
    "    '--n-features-options', '[2,4,6]', \n",
    "    '--l2-reg-options', '[0.1,0.2,0.3,0.5]'\n",
    "])\n",
    "arguments = {\"job_dir\": JOB_DIR, \"args\": ARGS}\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
