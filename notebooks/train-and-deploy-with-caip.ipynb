{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy with Cloud AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training image\n",
    "### Use Cloud Build with Kaniko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [builds/use_kaniko].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set builds/use_kaniko True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "APP_FOLDER = '../training_app'\n",
    "os.makedirs(APP_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../training_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile $APP_FOLDER/Dockerfile\n",
    "\n",
    "FROM gcr.io/jk-sandbox12/ai_notebook_custom:latest\n",
    "WORKDIR /app\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../training_app/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $APP_FOLDER/train.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import fire\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def select_model(X, y, n_features_options, l2_reg_options):\n",
    "    \n",
    "  # Set up grid search\n",
    "  pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('regress', Ridge())\n",
    "  ])\n",
    "\n",
    "  param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': n_features_options,\n",
    "        'regress': [Ridge()],\n",
    "        'regress__alpha': l2_reg_options\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': ['passthrough'],\n",
    "        'regress': [PLSRegression(scale=False)],\n",
    "        'regress__n_components': n_features_options\n",
    "    }\n",
    "  ]\n",
    "\n",
    "  grid = GridSearchCV(pipeline, cv=10, n_jobs=None, param_grid=param_grid, scoring='neg_mean_squared_error', iid=False)\n",
    "\n",
    "  grid.fit(X, y)\n",
    "\n",
    "  return grid\n",
    "\n",
    "def train(job_dir, data_path, n_features_options, l2_reg_options):\n",
    "    \n",
    "  # Load data from GCS\n",
    "  df_train = pd.read_csv(data_path, index_col=0)\n",
    "  y = df_train.octane\n",
    "  X = df_train.drop('octane', axis=1)\n",
    "    \n",
    "  # Find the best model\n",
    "  y = df_train.octane\n",
    "  X = df_train.drop('octane', axis=1)\n",
    "  grid = select_model(X, y, n_features_options, l2_reg_options)\n",
    "\n",
    "  logging.info(\"Best estimator: {}\".format(grid.best_params_))\n",
    "  logging.info(\"Best score: {}\".format(grid.best_score_))\n",
    "    \n",
    "  # Retrain the best model on a full dataset\n",
    "  best_estimator = grid.best_estimator_\n",
    "  trained_pipeline = best_estimator.fit(X, y)\n",
    "\n",
    "  # Save the model\n",
    "  model_filename = 'model.joblib'\n",
    "  joblib.dump(value=trained_pipeline, filename=model_filename)\n",
    "  gcs_model_path = \"{}/trained_model/{}\".format(job_dir, model_filename)\n",
    "  subprocess.check_call(['gsutil', 'cp', model_filename, gcs_model_path], stderr=sys.stdout)\n",
    "  logging.info(\"Saved model in: {}\".format(gcs_model_path))\n",
    "  \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "  logging.basicConfig(level=logging.INFO)\n",
    "  fire.Fire(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 2.4 KiB before compression.\n",
      "Uploading tarball of [../training_app] to [gs://jk-sandbox12_cloudbuild/source/1566143514.01-315a334aeb6746bc9f1e773e41c4dd35.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jk-sandbox12/builds/6378c3af-f828-48bd-a18b-ad36ba1f040b].\n",
      "Logs are available at [https://console.cloud.google.com/gcr/builds/6378c3af-f828-48bd-a18b-ad36ba1f040b?project=532679469893].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"6378c3af-f828-48bd-a18b-ad36ba1f040b\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jk-sandbox12_cloudbuild/source/1566143514.01-315a334aeb6746bc9f1e773e41c4dd35.tgz#1566143514947598\n",
      "Copying gs://jk-sandbox12_cloudbuild/source/1566143514.01-315a334aeb6746bc9f1e773e41c4dd35.tgz#1566143514947598...\n",
      "/ [1 files][  1.1 KiB/  1.1 KiB]                                                \n",
      "Operation completed over 1 objects/1.1 KiB.                                      \n",
      "BUILD\n",
      "Pulling image: gcr.io/kaniko-project/executor:latest\n",
      "latest: Pulling from kaniko-project/executor\n",
      "Digest: sha256:78d44ec4e9cb5545d7f85c1924695c89503ded86a59f92c7ae658afa3cff5400\n",
      "Status: Downloaded newer image for gcr.io/kaniko-project/executor:latest\n",
      "gcr.io/kaniko-project/executor:latest\n",
      "\u001b[36mINFO\u001b[0m[0001] Resolved base name gcr.io/jk-sandbox12/ai_notebook_custom:latest to gcr.io/jk-sandbox12/ai_notebook_custom:latest \n",
      "\u001b[36mINFO\u001b[0m[0001] Resolved base name gcr.io/jk-sandbox12/ai_notebook_custom:latest to gcr.io/jk-sandbox12/ai_notebook_custom:latest \n",
      "\u001b[36mINFO\u001b[0m[0001] Downloading base image gcr.io/jk-sandbox12/ai_notebook_custom:latest \n",
      "\u001b[36mINFO\u001b[0m[0001] Error while retrieving image from cache: getting file info: stat /cache/sha256:ef2d473cd9bb0fe5edb5035b76a6c79eeba2e308257bdb2b21b19a1909373d71: no such file or directory \n",
      "\u001b[36mINFO\u001b[0m[0001] Downloading base image gcr.io/jk-sandbox12/ai_notebook_custom:latest \n",
      "error building image: unsupported status code 404; body: <?xml version='1.0' encoding='UTF-8'?><Error><Code>NoSuchKey</Code><Message>The specified key does not exist.</Message><Details>No such object: artifacts.jk-sandbox12.appspot.com/containers/images/sha256:c6b04f9492dff16497ba6b9b214f410c6ce94cffd124099ad1055c2a11537a03</Details></Error>\n",
      "ERROR\n",
      "ERROR: build step 0 \"gcr.io/kaniko-project/executor:latest\" failed: exit status 1\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.builds.submit) build 6378c3af-f828-48bd-a18b-ad36ba1f040b completed with status \"FAILURE\"\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = !gcloud config list project --format \"value(core.project)\"\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "IMAGE_REPO_NAME=\"training_app\"\n",
    "IMAGE_TAG=\"latest\"\n",
    "IMAGE_URI=\"gcr.io/{}/{}:{}\".format(PROJECT_ID, IMAGE_REPO_NAME, IMAGE_TAG)\n",
    "\n",
    "!gcloud builds submit --tag $IMAGE_URI $APP_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [JOB_20190818_150726] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe JOB_20190818_150726\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs JOB_20190818_150726\n",
      "jobId: JOB_20190818_150726\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "JOB_NAME=\"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "REGION=\"us-west1\"\n",
    "SCALE_TIER=\"BASIC\"\n",
    "JOB_DIR=\"gs://jk-demo-jobdir/{}\".format(JOB_NAME)\n",
    "\n",
    "DATA_PATH=\"gs://jk-demo-datasets/gasdata/gasdata.csv\"\n",
    "N_FEATURES_OPTIONS=\"[2,4,6]\"\n",
    "L2_REG_OPTIONS=\"[0.1,0.2,0.3,0.5]\"\n",
    "\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "--region $REGION \\\n",
    "--job-dir $JOB_DIR \\\n",
    "--master-image-uri $IMAGE_URI \\\n",
    "--scale-tier $SCALE_TIER \\\n",
    "-- \\\n",
    "--data_path $DATA_PATH \\\n",
    "--n_features_options $N_FEATURES_OPTIONS \\\n",
    "--l2_reg_options $L2_REG_OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-08-18T15:07:28Z'\n",
      "etag: 3G1-3xv97no=\n",
      "jobId: JOB_20190818_150726\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path\n",
      "  - gs://jk-demo-datasets/gasdata/gasdata.csv\n",
      "  - --n_features_options\n",
      "  - '[2,4,6]'\n",
      "  - --l2_reg_options\n",
      "  - '[0.1,0.2,0.3,0.5]'\n",
      "  jobDir: gs://jk-demo-jobdir/JOB_20190818_150726\n",
      "  masterConfig:\n",
      "    imageUri: gcr.io/jk-sandbox12/training_app:latest\n",
      "  region: us-west1\n",
      "trainingOutput: {}\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/JOB_20190818_150726?project=jk-sandbox12\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2FJOB_20190818_150726&project=jk-sandbox12\n",
      "INFO\t2019-08-18 15:07:27 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-08-18 15:07:28 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-08-18 15:07:28 +0000\tservice\t\tJob JOB_20190818_150726 is queued.\n",
      "INFO\t2019-08-18 15:07:28 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-08-18 15:07:31 +0000\tservice\t\tWaiting for training program to start.\n",
      "ERROR\t2019-08-18 15:10:49 +0000\tmaster-replica-0\t\tINFO:root:Best estimator: {'reduce_dim': 'passthrough', 'regress': PLSRegression(copy=True, max_iter=500, n_components=6, scale=False, tol=1e-06), 'regress__n_components': 6}\n",
      "ERROR\t2019-08-18 15:10:49 +0000\tmaster-replica-0\t\tINFO:root:Best score: -0.04444602823372305\n",
      "INFO\t2019-08-18 15:10:50 +0000\tmaster-replica-0\t\tCopying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "INFO\t2019-08-18 15:10:51 +0000\tmaster-replica-0\t\t/ [0 files][    0.0 B/ 82.6 KiB]                                                \n",
      "INFO\t2019-08-18 15:10:51 +0000\tmaster-replica-0\t\t/ [1 files][ 82.6 KiB/ 82.6 KiB]                                                \n",
      "INFO\t2019-08-18 15:10:51 +0000\tmaster-replica-0\t\tOperation completed over 1 objects/82.6 KiB.                                     \n",
      "ERROR\t2019-08-18 15:10:51 +0000\tmaster-replica-0\t\tINFO:root:Saved model in: gs://jk-demo-jobdir/JOB_20190818_150726/trained_model/model.joblib\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe $JOB_NAME\n",
    "!gcloud ai-platform jobs stream-logs $JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training image with KFP SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
