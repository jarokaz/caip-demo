{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy with Cloud AI Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import googleapiclient.discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_APP_FOLDER = '../training_app/trainer'\n",
    "PREDICT_APP_FOLDER = '../predict_app'\n",
    "TRAINING_DATA_PATH = 'gs://jk-demo-datasets/gasdata/training.csv'\n",
    "TESTING_DATA_PATH = 'gs://jk-demo-datasets/gasdata/testing.csv'\n",
    "REGION = \"us-central1\"\n",
    "ARTIFACT_BUCKET = \"gs://jk-demo-artifacts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TRAINING_APP_FOLDER, exist_ok=True)\n",
    "!touch $TRAINING_APP_FOLDER/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../training_app/trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAINING_APP_FOLDER/train.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import fire\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def train(job_dir, data_path, n_features_options, l2_reg_options):\n",
    "    \n",
    "  # Load data from GCS\n",
    "  df_train = pd.read_csv(data_path)\n",
    "\n",
    "  y = df_train.octane\n",
    "  X = df_train.drop('octane', axis=1)\n",
    "    \n",
    "  pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('regress', Ridge())\n",
    "  ])\n",
    "\n",
    "  param_grid = [\n",
    "    {\n",
    "      'reduce_dim__n_components': n_features_options,\n",
    "      'regress__alpha': l2_reg_options\n",
    "    }\n",
    "  ]\n",
    "\n",
    "  grid = GridSearchCV(pipeline, cv=10, n_jobs=None, param_grid=param_grid, scoring='neg_mean_squared_error', iid=False)\n",
    "  \n",
    "  grid.fit(X, y)\n",
    "\n",
    "  logging.info(\"Best estimator: {}\".format(grid.best_params_))\n",
    "  logging.info(\"Best score: {}\".format(grid.best_score_))\n",
    "    \n",
    "  # Retrain the best model on a full dataset\n",
    "  best_estimator = grid.best_estimator_\n",
    "  trained_pipeline = best_estimator.fit(X, y)\n",
    "\n",
    "  # Save the model\n",
    "  model_filename = 'model.joblib'\n",
    "  joblib.dump(value=trained_pipeline, filename=model_filename)\n",
    "  gcs_model_path = \"{}/trained_model/{}\".format(job_dir, model_filename)\n",
    "  subprocess.check_call(['gsutil', 'cp', model_filename, gcs_model_path], stderr=sys.stdout)\n",
    "  logging.info(\"Saved model in: {}\".format(gcs_model_path)) \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "  logging.basicConfig(level=logging.INFO)\n",
    "  fire.Fire(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../training_app/trainer/../setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $TRAINING_APP_FOLDER/../setup.py\n",
    "\n",
    "from setuptools import find_packages\n",
    "from setuptools import setup\n",
    "\n",
    "REQUIRED_PACKAGES = ['fire', 'gcsfs']\n",
    "\n",
    "setup(\n",
    "    name='trainer',\n",
    "    version='0.1',\n",
    "    install_requires=REQUIRED_PACKAGES,\n",
    "    packages=find_packages(),\n",
    "    include_package_data=True,\n",
    "    description='My training application package.'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "SCALE_TIER = \"BASIC\"\n",
    "#JOB_DIR = \"gs://jk-demo-jobdir/{}\".format(JOB_NAME)\n",
    "MODULE_NAME = \"trainer.train\"\n",
    "RUNTIME_VERSION = \"1.14\"\n",
    "PYTHON_VERSION = \"3.5\"\n",
    "\n",
    "N_FEATURES_OPTIONS=\"[2,4,6]\"\n",
    "L2_REG_OPTIONS=\"[0.1,0.2,0.3,0.5]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [JOB_20190820_185030] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs describe JOB_20190820_185030\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai-platform jobs stream-logs JOB_20190820_185030\n",
      "jobId: JOB_20190820_185030\n",
      "state: QUEUED\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "--region $REGION \\\n",
    "--job-dir $ARTIFACT_BUCKET/jobs/$JOB_NAME \\\n",
    "--package-path $TRAINING_APP_FOLDER \\\n",
    "--module-name $MODULE_NAME \\\n",
    "--scale-tier $SCALE_TIER \\\n",
    "--python-version $PYTHON_VERSION \\\n",
    "--runtime-version $RUNTIME_VERSION \\\n",
    "-- \\\n",
    "--data_path $TRAINING_DATA_PATH \\\n",
    "--n_features_options $N_FEATURES_OPTIONS \\\n",
    "--l2_reg_options $L2_REG_OPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-08-20T18:50:34Z'\n",
      "etag: skWF-jPO2RI=\n",
      "jobId: JOB_20190820_185030\n",
      "state: PREPARING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path\n",
      "  - gs://jk-demo-datasets/gasdata/training.csv\n",
      "  - --n_features_options\n",
      "  - '[2,4,6]'\n",
      "  - --l2_reg_options\n",
      "  - '[0.1,0.2,0.3,0.5]'\n",
      "  jobDir: gs://jk-demo-artifacts/jobs/JOB_20190820_185030\n",
      "  packageUris:\n",
      "  - gs://jk-demo-artifacts/jobs/JOB_20190820_185030/packages/a2b25d0d356d4ec70cba370d0cce00dbc11690faa6f99a820264072517d6a8bf/trainer-0.1.tar.gz\n",
      "  pythonModule: trainer.train\n",
      "  pythonVersion: '3.5'\n",
      "  region: us-west1\n",
      "  runtimeVersion: '1.14'\n",
      "trainingOutput: {}\n",
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/mlengine/jobs/JOB_20190820_185030?project=jk-demo1\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2FJOB_20190820_185030&project=jk-demo1\n",
      "INFO\t2019-08-20 18:50:34 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-08-20 18:50:34 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-08-20 18:50:34 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-08-20 18:50:34 +0000\tservice\t\tJob JOB_20190820_185030 is queued.\n",
      "INFO\t2019-08-20 18:50:38 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-08-20 18:51:17 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://jk-demo-artifacts/jobs/JOB_20190820_185030/packages/a2b25d0d356d4ec70cba370d0cce00dbc11690faa6f99a820264072517d6a8bf/trainer-0.1.tar.gz\"],  \"python_module\": \"trainer.train\",  \"args\": [\"--data_path\", \"gs://jk-demo-datasets/gasdata/training.csv\", \"--n_features_options\", \"[2,4,6]\", \"--l2_reg_options\", \"[0.1,0.2,0.3,0.5]\"],  \"region\": \"us-west1\",  \"runtime_version\": \"1.14\",  \"job_dir\": \"gs://jk-demo-artifacts/jobs/JOB_20190820_185030\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "WARNING\t2019-08-20 18:51:33 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:676: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "WARNING\t2019-08-20 18:51:33 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:677: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "WARNING\t2019-08-20 18:51:33 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:678: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "WARNING\t2019-08-20 18:51:33 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:681: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "WARNING\t2019-08-20 18:51:33 +0000\tmaster-replica-0\t\tFrom /runcloudml.py:682: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "INFO\t2019-08-20 18:51:38 +0000\tmaster-replica-0\t\tRunning module trainer.train.\n",
      "INFO\t2019-08-20 18:51:38 +0000\tmaster-replica-0\t\tDownloading the package: gs://jk-demo-artifacts/jobs/JOB_20190820_185030/packages/a2b25d0d356d4ec70cba370d0cce00dbc11690faa6f99a820264072517d6a8bf/trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:38 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://jk-demo-artifacts/jobs/JOB_20190820_185030/packages/a2b25d0d356d4ec70cba370d0cce00dbc11690faa6f99a820264072517d6a8bf/trainer-0.1.tar.gz trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:40 +0000\tmaster-replica-0\t\tInstalling the package: gs://jk-demo-artifacts/jobs/JOB_20190820_185030/packages/a2b25d0d356d4ec70cba370d0cce00dbc11690faa6f99a820264072517d6a8bf/trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:40 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:41 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\t  Created wheel for trainer: filename=trainer-0.1-cp35-none-any.whl size=2129 sha256=956c4c5153fb0a3300617a7a40945e52a31af485eae113a2ac904ec3c0e7d41d\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/e8/0c/c7/b77d64796dbbac82503870c4881d606fa27e63942e07c75f0e\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tSuccessfully built trainer\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tInstalling collected packages: trainer\n",
      "INFO\t2019-08-20 18:51:42 +0000\tmaster-replica-0\t\tSuccessfully installed trainer-0.1\n",
      "ERROR\t2019-08-20 18:51:44 +0000\tmaster-replica-0\t\tWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\n",
      "ERROR\t2019-08-20 18:51:44 +0000\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-08-20 18:51:44 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:44 +0000\tmaster-replica-0\t\tProcessing ./trainer-0.1.tar.gz\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\tCollecting fire (from trainer==0.1)\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\t  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:45 +0000\tmaster-replica-0\t\tCollecting gcsfs (from trainer==0.1)\n",
      "INFO\t2019-08-20 18:51:46 +0000\tmaster-replica-0\t\t  Downloading https://files.pythonhosted.org/packages/f8/35/65faba9cdf8f6df166ec4005cf1722fb699c034380f6acb897f354b464a7/gcsfs-0.2.3.tar.gz (51kB)\n",
      "INFO\t2019-08-20 18:51:46 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:46 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:46 +0000\tmaster-replica-0\t\tRequirement already satisfied: six in /usr/local/lib/python3.5/dist-packages (from fire->trainer==0.1) (1.12.0)\n",
      "INFO\t2019-08-20 18:51:46 +0000\tmaster-replica-0\t\tRequirement already satisfied: termcolor in /usr/local/lib/python3.5/dist-packages (from fire->trainer==0.1) (1.1.0)\n",
      "INFO\t2019-08-20 18:51:46 +0000\tmaster-replica-0\t\tRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.5/dist-packages (from gcsfs->trainer==0.1) (1.6.3)\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\tCollecting google-auth-oauthlib (from gcsfs->trainer==0.1)\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\t  Downloading https://files.pythonhosted.org/packages/74/a2/1323b1bce9935ac948cd4863509de16cf852cd80b12dd29e648c65fea93d/google_auth_oauthlib-0.4.0-py2.py3-none-any.whl\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\tRequirement already satisfied: requests in /usr/local/lib/python3.5/dist-packages (from gcsfs->trainer==0.1) (2.19.0)\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\tCollecting decorator (from gcsfs->trainer==0.1)\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\t  Downloading https://files.pythonhosted.org/packages/5f/88/0075e461560a1e750a0dcbf77f1d9de775028c37a19a346a6c565a257399/decorator-4.4.0-py2.py3-none-any.whl\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\tRequirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.5/dist-packages (from google-auth>=1.2->gcsfs->trainer==0.1) (3.1.1)\n",
      "INFO\t2019-08-20 18:51:47 +0000\tmaster-replica-0\t\tRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.5/dist-packages (from google-auth>=1.2->gcsfs->trainer==0.1) (0.2.6)\n",
      "INFO\t2019-08-20 18:51:48 +0000\tmaster-replica-0\t\tRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.5/dist-packages (from google-auth>=1.2->gcsfs->trainer==0.1) (4.0)\n",
      "INFO\t2019-08-20 18:51:48 +0000\tmaster-replica-0\t\tCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib->gcsfs->trainer==0.1)\n",
      "INFO\t2019-08-20 18:51:48 +0000\tmaster-replica-0\t\t  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "INFO\t2019-08-20 18:51:48 +0000\tmaster-replica-0\t\tRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests->gcsfs->trainer==0.1) (2019.6.16)\n",
      "INFO\t2019-08-20 18:51:48 +0000\tmaster-replica-0\t\tRequirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests->gcsfs->trainer==0.1) (2.7)\n",
      "INFO\t2019-08-20 18:51:49 +0000\tmaster-replica-0\t\tRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests->gcsfs->trainer==0.1) (3.0.4)\n",
      "INFO\t2019-08-20 18:51:49 +0000\tmaster-replica-0\t\tRequirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests->gcsfs->trainer==0.1) (1.23)\n",
      "INFO\t2019-08-20 18:51:49 +0000\tmaster-replica-0\t\tRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.5/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->trainer==0.1) (0.4.6)\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\tCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->trainer==0.1)\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\t  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: trainer, fire, gcsfs\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): started\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\t  Building wheel for trainer (setup.py): finished with status 'done'\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\t  Created wheel for trainer: filename=trainer-0.1-cp35-none-any.whl size=2129 sha256=52e96595b3d985b9d08ea9114494d7227444b00dd9ae45e215491ef4e9ac0861\n",
      "INFO\t2019-08-20 18:51:50 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/e8/0c/c7/b77d64796dbbac82503870c4881d606fa27e63942e07c75f0e\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\t  Building wheel for fire (setup.py): started\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\t  Building wheel for fire (setup.py): finished with status 'done'\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\t  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103527 sha256=d2455145699618bc0114a922d28a4b4793dcc34da6ffc158d8ed5bb2c6604a45\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
      "INFO\t2019-08-20 18:51:51 +0000\tmaster-replica-0\t\t  Building wheel for gcsfs (setup.py): started\n",
      "INFO\t2019-08-20 18:51:52 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-08-20 18:51:52 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-08-20 18:51:52 +0000\tmaster-replica-0\t\t  Building wheel for gcsfs (setup.py): finished with status 'done'\n",
      "INFO\t2019-08-20 18:51:52 +0000\tmaster-replica-0\t\t  Created wheel for gcsfs: filename=gcsfs-0.2.3-cp35-none-any.whl size=27597 sha256=dc9beb1fb17cab049e0fb868e69ed217f969905e09bc54832b1ef17b85e39583\n",
      "INFO\t2019-08-20 18:51:52 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/cf/68/29/276205e6d8fb4de46f5cbe6098c26cea34eae21334f636b24a\n",
      "INFO\t2019-08-20 18:51:52 +0000\tmaster-replica-0\t\tSuccessfully built trainer fire gcsfs\n",
      "INFO\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\tInstalling collected packages: fire, oauthlib, requests-oauthlib, google-auth-oauthlib, decorator, gcsfs, trainer\n",
      "ERROR\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t  WARNING: The script google-oauthlib-tool is installed in '/root/.local/bin' which is not on PATH.\n",
      "ERROR\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t  WARNING: The script gcsfuse is installed in '/root/.local/bin' which is not on PATH.\n",
      "ERROR\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "INFO\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t  Found existing installation: trainer 0.1\n",
      "INFO\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t    Uninstalling trainer-0.1:\n",
      "INFO\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\t      Successfully uninstalled trainer-0.1\n",
      "INFO\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\tSuccessfully installed decorator-4.4.0 fire-0.2.1 gcsfs-0.2.3 google-auth-oauthlib-0.4.0 oauthlib-3.1.0 requests-oauthlib-1.2.0 trainer-0.1\n",
      "ERROR\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\tWARNING: You are using pip version 19.2.1, however version 19.2.2 is available.\n",
      "ERROR\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-08-20 18:51:55 +0000\tmaster-replica-0\t\tRunning command: python3 -m trainer.train --data_path gs://jk-demo-datasets/gasdata/training.csv --n_features_options [2,4,6] --l2_reg_options [0.1,0.2,0.3,0.5] --job-dir gs://jk-demo-artifacts/jobs/JOB_20190820_185030\n",
      "INFO\t2019-08-20 18:52:01 +0000\tmaster-replica-0\t\tBest estimator: {'regress__alpha': 0.1, 'reduce_dim__n_components': 6}\n",
      "INFO\t2019-08-20 18:52:01 +0000\tmaster-replica-0\t\tBest score: -0.046490190253110665\n",
      "INFO\t2019-08-20 18:52:02 +0000\tmaster-replica-0\t\tCopying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\t/ [0 files][    0.0 B/ 33.1 KiB]                                                \n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\t/ [1 files][ 33.1 KiB/ 33.1 KiB]                                                \n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\tOperation completed over 1 objects/33.1 KiB.                                     \n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\tSaved model in: gs://jk-demo-artifacts/jobs/JOB_20190820_185030/trained_model/model.joblib\n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-08-20 18:52:03 +0000\tmaster-replica-0\t\tTask completed successfully.\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform jobs describe $JOB_NAME\n",
    "!gcloud ai-platform jobs stream-logs $JOB_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy using AI Platform Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gas_octane_regression\"\n",
    "LABELS = \"task=regression,domain=chemometrics\"\n",
    "#MODEL_PATH = \"{}/trained_model/\".format(JOB_DIR)\n",
    "VERSION_NAME = \"v01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/jk-demo1/models/gas_octane_regression].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create  $MODEL_NAME \\\n",
    "--regions=$REGION \\\n",
    "--labels=$LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform versions create $VERSION_NAME \\\n",
    "--model=$MODEL_NAME \\\n",
    "--origin=$ARTIFACT_BUCKET/jobs/$JOB_NAME/trained_model/ \\\n",
    "--runtime-version=1.14 \\\n",
    "--framework=scikit-learn \\\n",
    "--python-version=3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "#### Prepare a file with test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = 'instances.json'\n",
    "\n",
    "df_test = pd.read_csv(TESTING_DATA_PATH).drop('octane', axis=1)\n",
    "with open(INPUT_FILE, \"w\") as f:\n",
    "  for index, row in df_test.iterrows():\n",
    "    f.write(json.dumps(list(row.values)))\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.61274117546486, 88.78144180442887, 86.60147562277632, 86.37821707761988, 84.57226241557935, 88.60871164935777]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict \\\n",
    "--model $MODEL_NAME \\\n",
    "--version $VERSION_NAME \\\n",
    "--json-instances $INPUT_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy with a custom prediction routine\n",
    "### Create a predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PREDICT_APP_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../predict_app/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PREDICT_APP_FOLDER/predict.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class OctaneRegressor(object):\n",
    "    \"\"\"A custom prediction routine for Octane regressor\"\"\"\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        \"\"\"Stores the model loaded in from_path\"\"\"\n",
    "        self._model = model\n",
    "        \n",
    "    def predict(self, instances, **kwargs):\n",
    "        \"\"\"Runs inference\"\"\"\n",
    "    \n",
    "        outputs = self._model.predict(np.asarray(instances))\n",
    "        \n",
    "        return outputs.tolist()\n",
    "\n",
    "        \n",
    "    @classmethod\n",
    "    def from_path(cls, model_dir):\n",
    "        \"\"\"Loads the model from the joblib file\"\"\"\n",
    "        model_path = os.path.join(model_dir, 'model.joblib')\n",
    "        model = joblib.load(model_path)\n",
    "        \n",
    "        \n",
    "        return cls(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a source distribution package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../predict_app/setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PREDICT_APP_FOLDER/setup.py\n",
    "\n",
    "from setuptools import setup\n",
    "\n",
    "setup(\n",
    "    name='custom-predictor',\n",
    "    description='Custom prediction routine.',\n",
    "    version='0.1',\n",
    "    scripts=['predict.py']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/caip-demo/predict_app\n",
      "running sdist\n",
      "running egg_info\n",
      "writing top-level names to custom_predictor.egg-info/top_level.txt\n",
      "writing dependency_links to custom_predictor.egg-info/dependency_links.txt\n",
      "writing custom_predictor.egg-info/PKG-INFO\n",
      "reading manifest file 'custom_predictor.egg-info/SOURCES.txt'\n",
      "writing manifest file 'custom_predictor.egg-info/SOURCES.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating custom-predictor-0.1\n",
      "creating custom-predictor-0.1/custom_predictor.egg-info\n",
      "copying files to custom-predictor-0.1...\n",
      "copying predict.py -> custom-predictor-0.1\n",
      "copying setup.py -> custom-predictor-0.1\n",
      "copying custom_predictor.egg-info/PKG-INFO -> custom-predictor-0.1/custom_predictor.egg-info\n",
      "copying custom_predictor.egg-info/SOURCES.txt -> custom-predictor-0.1/custom_predictor.egg-info\n",
      "copying custom_predictor.egg-info/dependency_links.txt -> custom-predictor-0.1/custom_predictor.egg-info\n",
      "copying custom_predictor.egg-info/top_level.txt -> custom-predictor-0.1/custom_predictor.egg-info\n",
      "Writing custom-predictor-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'custom-predictor-0.1' (and everything under it)\n",
      "/home/jupyter/caip-demo/notebooks\n"
     ]
    }
   ],
   "source": [
    "%cd $PREDICT_APP_FOLDER\n",
    "%run $PREDICT_APP_FOLDER/setup.py sdist --formats=gztar\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the source distribution package to GCS staging area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION_NAME = \"v05\"\n",
    "TARBALL_NAME = \"custom-predictor-0.1.tar.gz\"\n",
    "LOCAL_PATH = \"{}/dist/{}\".format(PREDICT_APP_FOLDER, TARBALL_NAME)\n",
    "GCS_PATH = \"{}/prediction_routines/{}/{}/{}\".format(ARTIFACT_BUCKET, MODEL_NAME, VERSION_NAME, TARBALL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../predict_app/dist/custom-predictor-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  985.0 B/  985.0 B]                                                \n",
      "Operation completed over 1 objects/985.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp $LOCAL_PATH $GCS_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating version (this might take a few minutes)......done.                    \n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai-platform versions create $VERSION_NAME \\\n",
    "--model=$MODEL_NAME \\\n",
    "--origin=$ARTIFACT_BUCKET/jobs/$JOB_NAME/trained_model/ \\\n",
    "--runtime-version=1.14 \\\n",
    "--python-version=3.5 \\\n",
    "--package-uris $GCS_PATH \\\n",
    "--prediction-class predict.OctaneRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.61274117546486, 88.78144180442887, 86.60147562277632, 86.37821707761988, 84.57226241557935, 88.60871164935777]\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform predict \\\n",
    "--model $MODEL_NAME \\\n",
    "--version $VERSION_NAME \\\n",
    "--json-instances $INPUT_FILE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
